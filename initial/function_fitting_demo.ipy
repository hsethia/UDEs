# %% [markdown]
# # Function Fitting Demo
# 
# In this example, we will fit a parameterised function to data. In the process of this,
# we will show how to solve optimization problems using scipy.optimize.

# %%
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize

# %% [markdown]
# We will consider the following hill function. Here we declare it as a function of its
# parameters and a single variable.

# %%
def hill_function(X, ps):
    v, K = ps
    return v * X**2 / (K**2 + X**2)

# %% [markdown]
# Next we set a true parameter set (which we later want to recover).

# %%
v = 2.0
K = 1.2
ps_true = [v, K]

# %% [markdown]
# For reference, we plot the function.

# %%
x_grid = np.arange(0.0, 5.1, 0.1)
y_vals = np.array([hill_function(x, ps_true) for x in x_grid])

plt.figure(figsize=(10, 6))
plt.plot(x_grid, y_vals, label='True function', linewidth=3)
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# %% [markdown]
# Next, we generate some synthetic data by sampling the true function and adding noise.

# %%
np.random.seed(42)  # For reproducibility
x_samples = np.arange(0.0, 5.1, 0.5)
y_samples = np.array([hill_function(x, ps_true) * (0.9 + 0.2 * np.random.rand()) for x in x_samples])

# %% [markdown]
# For reference, we plot the sampled data (in the same plotting plane as the true function).

# %%
plt.figure(figsize=(10, 6))
plt.plot(x_grid, y_vals, label='True function', linewidth=3)
plt.scatter(x_samples, y_samples, label='Sampled data', s=100, alpha=0.7)
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# %% [markdown]
# Now assuming that we have the data, but not the true parameter values, is it possible to recover these?
# To do this, we first define a loss function, which quantifies how good a proposed parameter set
# makes our function fit the data. Here, we will simply, for a proposed parameter set, for
# each x sample, evaluate the function and compute the squared difference to the data.
# We sum these up for all data points to get the overall loss.

# %%
def loss_function(ps_proposed):
    diff_tot = 0.0
    for i in range(len(y_samples)):
        y_proposed = hill_function(x_samples[i], ps_proposed)
        diff_tot += (y_proposed - y_samples[i])**2
    return diff_tot

# %% [markdown]
# Here, for two different proposed parameter values, we print the loss function value and
# show the fit. We note that, the parameter set that is close to the true value yields a better
# fit to the data and a smaller loss function value.

# %%
ps_proposed_1 = [1.8, 1.3]
ps_proposed_2 = [1.2, 1.8]

def plot_proposed_fit(ps_proposed):
    loss_func_eval = loss_function(ps_proposed)
    y_vals_proposed = np.array([hill_function(x, ps_proposed) for x in x_grid])
    
    plt.plot(x_grid, y_vals_proposed, label='Proposed fit', linewidth=3, linestyle='--', color='blue')
    plt.scatter(x_samples, y_samples, label='Sampled data', s=100, alpha=0.7)
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title(f'Loss: {loss_func_eval:.2f}')
    plt.legend()
    plt.grid(True, alpha=0.3)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

plt.sca(ax1)
plot_proposed_fit(ps_proposed_1)

plt.sca(ax2)
plot_proposed_fit(ps_proposed_2)

plt.tight_layout()
plt.show()

# %% [markdown]
# Now, plausibly, the parameter set that minimises the loss function should yield a good fit
# to the data. Potentially, this could be an approach for finding the true parameter set.
# Here, we will use scipy.optimize to find which input minimises our loss function.

# %%
# Initial random guess
ps_init = [np.random.rand(), np.random.rand()]

# Solve the optimization problem
result = minimize(loss_function, ps_init, method='BFGS')

print(f"Optimization successful: {result.success}")
print(f"Fitted parameters: {result.x}")
print(f"True parameters: {ps_true}")

# %% [markdown]
# We can confirm that we got the correct parameter set. The fit is non-exact due to the noise in the data.
# Finally, we can plot the fitted function against the true one and the data.

# %%
y_vals_fitted = np.array([hill_function(x, result.x) for x in x_grid])

plt.figure(figsize=(10, 6))
plt.plot(x_grid, y_vals, label='True function', linewidth=3)
plt.scatter(x_samples, y_samples, label='Sampled data', s=100, alpha=0.7)
plt.plot(x_grid, y_vals_fitted, label='Fitted function', linewidth=3, color='blue', linestyle='--')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

